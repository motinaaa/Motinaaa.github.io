[
  {
    "objectID": "posts/blog6/index.html",
    "href": "posts/blog6/index.html",
    "title": "Badge is Coool!",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nYes! It’s working :)\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nR package dependencies are easier to manage and reproducible environments are easier to create with the renv package. The use of renv means you will spend less time worrying about package version mismatches and more time developing or analyzing.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nBefore I pushed the changes to my blog4 repo, I did a few things to make sure everything was in order.\nFirst, I hit up “renv::init()” to get my R environment all set up for this project.\nThen I called “renv::dependencies” to make sure all my package dependencies were good to go.\nAfter that, I hit up “renv::snapshot()” to save my project library in case I needed to roll back my updates.\nNext, I added “check-yaml.yaml” to my workflow folder because the badge code shows the status of the workflow defined in my “.github/workflows” directory. I also added “schema.json” and “schema.yaml” to my “.github” folder and copied and pasted the ymal and json code from blog 5.\nThat’s when I spotted a problem: the ymal in the read.rmd file for blog 4 was messed up. The dates weren’t in quotation marks ““, and the categories were spelled like”category.” So, I fixed those issues and pushed everything up to my repo. Easy peasy! I followed the same process for blog 6, and now both badges are showing “passing.”\nSubmit this blog post to your blog-6 repo.\n\n\n\nReuseCC BY-NC-SACitationBibTeX citation:@online{motina2023,\n  author = {Motina},\n  title = {Badge Is {Coool!}},\n  date = {2023-03-02},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMotina. 2023. “Badge Is Coool!” March 2, 2023."
  },
  {
    "objectID": "posts/blog7/index.html#prompt",
    "href": "posts/blog7/index.html#prompt",
    "title": "La la la license",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nToday’s most common permissive licenses are the MIT and Apache licenses; older permissive licenses include the various forms of the BSD license. A copyleft license is typically the GPL, which allows you to freely modify and copy the code for your own personal use. However, you must also license the modified version or complete bundle with the GPL if you publish it or bundle it with other code. ggplot2 is licensed under the MIT + file license.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3?\nOnce you’ve downloaded the package from GitHub, get package info with devtools::session_info() and filter for dependencies.Lab 3 Team 1’s package dependencies are listed below:\n  pkg_deps.package pkg_deps.ondiskversion\n1           askpass                    1.1\n2               cli                  3.6.0\n3             cpp11                  0.4.3\n4              curl                  5.0.0\n5             dplyr                  1.1.0\n6             fansi                  1.0.4\n7          generics                  0.1.3\n8              glue                  1.6.2\n9         lifecycle                  1.0.3\n10        lubridate                  1.9.2\n11         magrittr                  2.0.3\n12         pdftools                  3.3.3\n13           pillar                  1.8.1\n14        pkgconfig                  2.0.3\n15              png                  0.1-8\n16             qpdf                  1.3.2\n17               R6                  2.5.1\n18             Rcpp                 1.0.10\n19            rJava                  1.0-6\n20            rlang                  1.1.0\n21          stringi                 1.7.12\n22          stringr                  1.5.0\n23              sys                  3.4.1\n24        tabulizer                  0.2.3\n25    tabulizerjars                  1.0.1\n26            Team1             0.0.0.9000\n27           tibble                  3.2.0\n28       tidyselect                  1.2.0\n29       timechange                  0.2.0\n30             utf8                  1.2.3\n31            vctrs                  0.5.2\n32            withr                  2.5.0\nWhich licenses are involved? Are all of these dependencies required? Elaborate. It’s under the MIT license. Apparently there are more dependencies than I remember, but perhaps these are dependencies from the libraries we used.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nWe’re using license CC0 1.0 Universal in our LICENSE file. Various licenses give the user enough information about the repository and its files. In addition to allowing users to understand what parts or files can be used by them, the license also protects the author’s rights. Changing the license type is possible, but I won’t. The Creative Commons license family uses CC as a keyword.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nBased on Colin Fay’s book, I understood that GPL-3 licensed packages are compatible and accepted by CRAN. It is therefore possible to publish it in CRAN, but it must be approved by all contributors. Conversations and permission announcements can happen on Github between the contributors. Just pointed out what was in the book that wasn’t in the following information from ChatGPT.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "posts/blog7/index.html#submission",
    "href": "posts/blog7/index.html#submission",
    "title": "La la la license",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing.."
  },
  {
    "objectID": "posts/blog5/index.html#prompt",
    "href": "posts/blog5/index.html#prompt",
    "title": "The One Where Ethics Meet Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\n\n‘I was fired up’: Psychiatrist effort prompts retraction of antidepressant treatment paper The article discusses suspected research misconduct in two studies on the use of metformin and cilostazol as adjunctive therapies for depression. The studies were conducted in Egypt and published in two journals. Eric Ross, a psychiatrist, raised concerns about the studies after noticing data irregularities. One study was retracted by the journal Neurotherapeutics, while the other study is still under investigation by the publisher of CNS Neuroscience & Therapeutics. The corresponding author of the papers denies any wrongdoing and has threatened legal action. Sandve et al.’s rules for detecting scientific fraud and misconduct may have helped in this situation, particularly rule #2 (Avoid Manual Data Manipulation Steps) and rule #1 (For Every Result, Keep Track of How It Was Produced). 2. After reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\n\nRule 1 is a good practice to follow. Keeping track of how results were produced ensures that my analyses can be reproduced, which is a fundamental aspect of scientific research. Reproducibility enables others to verify my findings, and for me to check and validate my own work. Additionally, it can help me spot errors and identify areas for improvement, leading to more robust and accurate results. Finally, it can enhance the transparency and credibility of my research. Rule 9 could be difficult to follow for me. Connecting textual statements to underlying results requires careful organization and documentation of data and analysis, which can be time-consuming and challenging to maintain, especially for large and complex projects. Furthermore, the rule may require a significant shift in my workflow and documentation practices, which may be hard to implement in my ongoing project working with collaborators who have different documentation styles or preferences. ## Submission 1. Push your changes to your repository.\n\n\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Motina\"\ntitle: \"The One Where Ethics Meet Reproducibility\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "posts/blog4/index.html#prompt",
    "href": "posts/blog4/index.html#prompt",
    "title": "Split-Apply-Combine",
    "section": "Prompt:",
    "text": "Prompt:\nThe plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nFor the baseball case study, the goal is to calculate the “career year”, that is the number of years since the player started playing, for all players with ddply.\n\n#library(\"plyr\")\n#baseball <- ddply(baseball, .(id), transform, \n#cyear = year - min(year) + 1)\n\nThe same thing can be done with ‘dplyr’ by grouping the data based on the same IDs, mutating cyear column with the formula, arranging the rows according to the IDs, then ungrouping the data set.\n\n#library(\"dplyr\")\n#baseball <- baseball %>% group_by(id) %>% mutate(cyear = year - min(year) + 1) %>% arrange(baseball$id) %>% ungroup(id)\n\nA linear model was fitted to each player in the next example with dlply.\n\n#library(\"plyr\")\n#library(\"dplyr\")\n#library(\"tidyverse\")\n#library(\"broom\")\n#library(\"tidyr\")\n#library(\"ggplot2\")\n#library(\"purrr\")\n#library(\"reshape2\")\n#source(\"v40i01.R\")\n#model <- function(df) { lm (rbi / ab ~ cyear, data=df, na.action=na.omit) }\n#bmodels <- dlply(baseball, .(id), model)\n\nWe can do the same thing with dplyr.\n\n#library(\"dplyr\")\n#library(\"reshape2\")\n#library(\"ggforce\")\n#source(\"v40i01.R\")\n#bmodels <- baseball %>% group_by(id) %>% do(bmodels = lm(rbi / ab ~ cyear, data = baseball))\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nPrior to this, I just used apply() and lapply(). Since we work with different inputs and want different outputs, we need more functions to get different outputs. There may also be times when we need to do some functions on a part of data, not all, as well as different functions on different parts of data. Hence, we should split up the data into manageable pieces, analyze each piece individually and incorporate them back together. Therefore, these two functions are not enough.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps: Grouped data term is not really my cup of tea, we use split-apply-combine to break up large problems into manageable pieces, our big problem could be grouped or not.We can split whatever data object we have into meaningful chunks.\n\n\nSplit: The data is first split into groups based on one or more variables of interest. I would personally go for subsets instead of groups. In addition, it should be mentioned that in split phase we can coerces a data-frame to a list of vectors, divide a vector or data-frame into the groups defined by a factor, split a vector or the column of a data-frame into the groups defined by a factor.\n\n\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group. It’s important to mention the inputs and outputs, because we can apply a function to the margins of an array, each cell of a ragged array, over a list or vector, and so forth. We can actually apply the function of interest to each element in our divisions.\n\n\nCombine: The results of the operation applied to each group are then combined and returned as a single output. We can have different kinds of outputs, we can combine the results into a new object of the desired structure\n\n\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R. It should be mention that Group_by() function belongs to the dplyr package, and dplyr is the next iteration of plyr, focusing on only data frames. \n\n** You can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Motina Kashanian",
    "section": "",
    "text": "My name is Motahareh Kashanian, Feel free to call me Motina!\nI’m an industrial engineering PhD student specializing in supply chain design and management. However, I’ve always felt the need to visualize the results of my work in a tangible way with colors and graphics to truly feel the impact of my efforts. That’s why I’m exploring how to combine operations research, data analytics, and visualization to solve real-world problems that positively impact people’s lives.\nAlthough this journey can be challenging, I’m committed to making the most of this opportunity and collaborating with other experts to make a real difference. Let’s go out there and make a change together!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Education\nWelcome to my personal website! I’m a researcher, engineer, and soon to be singer!\nI graduated from Amirkabir University of Technology in 2016 with a B.Sc. in Industrial Engineering. During this time, I started developing my mathematical modeling and machine learning skills.\nOne year later I started the M.Sc. program in Industrial and Systems Engineering at Iran University of Science and Technology which I completed in 2020. While completing this degree, I worked on a sourcing plan for a sustainable biomass portfolio using multi-stage stochastic programming, including land-use suitability analyses using geographic information systems in order to ensure the continuity of biomass supply in the Iran’s bioethanol supply chain. I was able to publish my work in a peer-reviewed journal as the lead author.\nA desire to integrate supply chain and artificial intelligence led me to pursue a doctoral degree in Industrial and Manufacturing Systems Engineering at Iowa State University in 2021. As part of my academic journey, I have acquired several different skills, including supply-chain design and management, analytical and problem-solving skills, mathematical programming, simulations, and data mining techniques.\n\n\nResearch Interests\nA key aspect of my research will be to develop a problem-solving framework that can be applied to a wide range of Food-Energy-Water Nexus research topics, including supply chain management, crop yield prediction for sustainable agriculture, and energy management in electrical power systems. To make better predictions and decisions from data, I plan to combine optimization, simulation, statistics, and machine learning techniques.\nYou can also see more about my background on my CV.\n\n\nPersonal intersts\nI have a few passions in life that I absolutely love. Singing is at the top of my list - it’s such a freeing experience. When I’m not singing, I’m usually lost in a good book or catching up on my favorite movies and TV shows. And when it comes to fashion, I love experimenting with different colors and expressing myself through my outfits.\nThanks for visiting my site, and I am grateful for any feedback you may have!\nCheers,\nMotina (موتینا)"
  },
  {
    "objectID": "Motinaaa.github.io.html",
    "href": "Motinaaa.github.io.html",
    "title": "Motina Kashanian",
    "section": "",
    "text": "My name is Motahareh Kashanian, Feel free to call me Motina! I’m an industrial engineering PhD student specializing in supply chain design and management. However, I’ve always felt the need to visualize the results of my work in a tangible way with colors and graphics to truly feel the impact of my efforts. That’s why I’m exploring how to combine operations research, data analytics, and visualization to solve real-world problems that positively impact people’s lives.\nAlthough this journey can be challenging, I’m committed to making the most of this opportunity and collaborating with other experts to make a real difference. Let’s go out there and make a change together!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "La la la license\n\n\n\n\n\n\n\nAll that legal stuff…\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2023\n\n\nMotina\n\n\n\n\n\n\n  \n\n\n\n\nBadge is Coool!\n\n\n\n\n\n\n\nMore on reproducibility…\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2023\n\n\nMotina\n\n\n\n\n\n\n  \n\n\n\n\nSplit-Apply-Combine\n\n\n\n\n\n\n\nSplit-apply-combine\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nMotina\n\n\n\n\n\n\n  \n\n\n\n\nThe One Where Ethics Meet Reproducibility\n\n\n\n\n\n\n\nEthics and Reproducibility…\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\nMotina\n\n\n\n\n\n\nNo matching items"
  }
]